{
    "training" : {
        "epochs" : 100,
        "batch_size" : 2,
        "save_path" : "/home/anhkhoa/Conformer/saves",
        "train_path" : "/home/anhkhoa/transformer_transducer_speeQ/data/train.json",
        "dev_path" : "/home/anhkhoa/transformer_transducer_speeQ/data/dev.json",
        "test_path" : "/home/anhkhoa/transformer_transducer_speeQ/data/dev.json",
        "vocab_path" : "/home/anhkhoa/transformer_transducer_speeQ/data/vocab.json",
        "log_file" : "/home/anhkhoa/Conformer/logs/conformer.log",
        "reload" : false,
        "max_grad_norm" : 200
    },
    "optim" : {
        "type" : "adam",
        "lr" : 0.001,
        "weight_decay" : 0.0001,
        "decay_rate" : 0.5
    },
    "scheduler" : {
        "lr_init" : 0.001,
        "warmup_steps" : 10000
    },
    "rnnt_loss" : {
        "blank" : 0, 
        "reduction" : "mean"
    },
    "model_name" : "Conformer_Transducer",
    "encoder_params" : {
        "n_layers" : 3, 
        "d_model" : 144,
        "dim_expand" : 144,
        "ff_ratio" : 4,
        "num_heads" : 4,
        "kernel_size" : 31,
        "p_dropout" : 0.1,
        "conv_stride" : 1,
        "att_stride" : 1,
        "padding" :  "same",
        "in_features" : 200,
        "output_size" : 320,
        "conv_type" : 2,
        "conv_subsampling" : {
            "num_layers" : 2,
            "filters" : [64, 32],
            "kernel_size" : 3,
            "norm" : "batch",
            "act" : "swish"
        },
        "conv_subsampling_2" : {

        },
        "attention_type" : "mha",

        "spec_augment" : {
            "spec_augment" : true,
            "mF" : 2,
            "F" : 27,
            "mT" : 10,
            "pS" : 0.05
        }
    },


    "decoder_params" : {
        "dec" : {
            "embedding_size" : 512,
            "hidden_size" : 512,
            "vocab_size" : 4866,
            "output_size" : 320,
            "n_layers" : 1,
            "dropout" : 0.1
        }
    },

    "joint" : {
        "type" : "concat",
        "input_size" : 320,
        "inner_size" : 512,
        "vocab_size" : 4866
    },
    "vocab" : {
        "sos" : 1,
        "eos" : 2,
        "blank" : 0
    }
    


}